{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_norm_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record</th>\n",
       "      <th>date</th>\n",
       "      <th>address-zip5-homephone//days_since</th>\n",
       "      <th>address-zip5-homephone//prev_d14_count</th>\n",
       "      <th>address-zip5//days_since</th>\n",
       "      <th>address-zip5//prev_d14_count</th>\n",
       "      <th>address-zip5//prev_d1_count</th>\n",
       "      <th>address-zip5//prev_d1_d30_avg</th>\n",
       "      <th>address-zip5//prev_d30_count</th>\n",
       "      <th>address-zip5//prev_d3_count</th>\n",
       "      <th>...</th>\n",
       "      <th>name-dob//prev_d14_count</th>\n",
       "      <th>ssn-dob//days_since</th>\n",
       "      <th>ssn-firstname//days_since</th>\n",
       "      <th>ssn-lastname//days_since</th>\n",
       "      <th>ssn-lastname//prev_d30_count</th>\n",
       "      <th>ssn-name-dob//prev_d30_count</th>\n",
       "      <th>ssn-name//days_since</th>\n",
       "      <th>ssn-name//prev_d30_count</th>\n",
       "      <th>ssn//days_since</th>\n",
       "      <th>fraud_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>-1.566892</td>\n",
       "      <td>-0.070089</td>\n",
       "      <td>-1.54593</td>\n",
       "      <td>-0.079045</td>\n",
       "      <td>-0.049665</td>\n",
       "      <td>0.174181</td>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.057932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0686</td>\n",
       "      <td>-1.573035</td>\n",
       "      <td>-1.558702</td>\n",
       "      <td>-1.558716</td>\n",
       "      <td>-0.097983</td>\n",
       "      <td>-0.092594</td>\n",
       "      <td>-1.559231</td>\n",
       "      <td>-0.097773</td>\n",
       "      <td>-1.556639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>-1.566892</td>\n",
       "      <td>-0.070089</td>\n",
       "      <td>-1.54593</td>\n",
       "      <td>-0.079045</td>\n",
       "      <td>-0.049665</td>\n",
       "      <td>0.174181</td>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.057932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0686</td>\n",
       "      <td>-1.573035</td>\n",
       "      <td>-1.558702</td>\n",
       "      <td>-1.558716</td>\n",
       "      <td>-0.097983</td>\n",
       "      <td>-0.092594</td>\n",
       "      <td>-1.559231</td>\n",
       "      <td>-0.097773</td>\n",
       "      <td>-1.556639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>-1.566892</td>\n",
       "      <td>-0.070089</td>\n",
       "      <td>-1.54593</td>\n",
       "      <td>-0.079045</td>\n",
       "      <td>-0.049665</td>\n",
       "      <td>0.174181</td>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.057932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0686</td>\n",
       "      <td>-1.573035</td>\n",
       "      <td>-1.558702</td>\n",
       "      <td>-1.558716</td>\n",
       "      <td>-0.097983</td>\n",
       "      <td>-0.092594</td>\n",
       "      <td>-1.559231</td>\n",
       "      <td>-0.097773</td>\n",
       "      <td>-1.556639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>-1.566892</td>\n",
       "      <td>-0.070089</td>\n",
       "      <td>-1.54593</td>\n",
       "      <td>-0.079045</td>\n",
       "      <td>-0.049665</td>\n",
       "      <td>0.174181</td>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.057932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0686</td>\n",
       "      <td>-1.573035</td>\n",
       "      <td>-1.558702</td>\n",
       "      <td>-1.558716</td>\n",
       "      <td>-0.097983</td>\n",
       "      <td>-0.092594</td>\n",
       "      <td>-1.559231</td>\n",
       "      <td>-0.097773</td>\n",
       "      <td>-1.556639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>-1.566892</td>\n",
       "      <td>-0.070089</td>\n",
       "      <td>-1.54593</td>\n",
       "      <td>-0.079045</td>\n",
       "      <td>-0.049665</td>\n",
       "      <td>0.174181</td>\n",
       "      <td>-0.101958</td>\n",
       "      <td>-0.057932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0686</td>\n",
       "      <td>-1.573035</td>\n",
       "      <td>-1.558702</td>\n",
       "      <td>-1.558716</td>\n",
       "      <td>-0.097983</td>\n",
       "      <td>-0.092594</td>\n",
       "      <td>-1.559231</td>\n",
       "      <td>-0.097773</td>\n",
       "      <td>-1.556639</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   record        date  address-zip5-homephone//days_since  \\\n",
       "0       1  2016-01-01                           -1.566892   \n",
       "1       2  2016-01-01                           -1.566892   \n",
       "2       3  2016-01-01                           -1.566892   \n",
       "3       4  2016-01-01                           -1.566892   \n",
       "4       5  2016-01-01                           -1.566892   \n",
       "\n",
       "   address-zip5-homephone//prev_d14_count  address-zip5//days_since  \\\n",
       "0                               -0.070089                  -1.54593   \n",
       "1                               -0.070089                  -1.54593   \n",
       "2                               -0.070089                  -1.54593   \n",
       "3                               -0.070089                  -1.54593   \n",
       "4                               -0.070089                  -1.54593   \n",
       "\n",
       "   address-zip5//prev_d14_count  address-zip5//prev_d1_count  \\\n",
       "0                     -0.079045                    -0.049665   \n",
       "1                     -0.079045                    -0.049665   \n",
       "2                     -0.079045                    -0.049665   \n",
       "3                     -0.079045                    -0.049665   \n",
       "4                     -0.079045                    -0.049665   \n",
       "\n",
       "   address-zip5//prev_d1_d30_avg  address-zip5//prev_d30_count  \\\n",
       "0                       0.174181                     -0.101958   \n",
       "1                       0.174181                     -0.101958   \n",
       "2                       0.174181                     -0.101958   \n",
       "3                       0.174181                     -0.101958   \n",
       "4                       0.174181                     -0.101958   \n",
       "\n",
       "   address-zip5//prev_d3_count  ...  name-dob//prev_d14_count  \\\n",
       "0                    -0.057932  ...                   -0.0686   \n",
       "1                    -0.057932  ...                   -0.0686   \n",
       "2                    -0.057932  ...                   -0.0686   \n",
       "3                    -0.057932  ...                   -0.0686   \n",
       "4                    -0.057932  ...                   -0.0686   \n",
       "\n",
       "   ssn-dob//days_since  ssn-firstname//days_since  ssn-lastname//days_since  \\\n",
       "0            -1.573035                  -1.558702                 -1.558716   \n",
       "1            -1.573035                  -1.558702                 -1.558716   \n",
       "2            -1.573035                  -1.558702                 -1.558716   \n",
       "3            -1.573035                  -1.558702                 -1.558716   \n",
       "4            -1.573035                  -1.558702                 -1.558716   \n",
       "\n",
       "   ssn-lastname//prev_d30_count  ssn-name-dob//prev_d30_count  \\\n",
       "0                     -0.097983                     -0.092594   \n",
       "1                     -0.097983                     -0.092594   \n",
       "2                     -0.097983                     -0.092594   \n",
       "3                     -0.097983                     -0.092594   \n",
       "4                     -0.097983                     -0.092594   \n",
       "\n",
       "   ssn-name//days_since  ssn-name//prev_d30_count  ssn//days_since  \\\n",
       "0             -1.559231                 -0.097773        -1.556639   \n",
       "1             -1.559231                 -0.097773        -1.556639   \n",
       "2             -1.559231                 -0.097773        -1.556639   \n",
       "3             -1.559231                 -0.097773        -1.556639   \n",
       "4             -1.559231                 -0.097773        -1.556639   \n",
       "\n",
       "   fraud_label  \n",
       "0            0  \n",
       "1            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [i for i in df.columns if i != 'fraud_label']\n",
    "cols.append('fraud_label')\n",
    "df = df[cols]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running code below, make sure the columns in your dataframe is similar to the one above, where:\n",
    " - Column 0 = record\n",
    " - Column 1 = date\n",
    " - Last Column = fraud_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test/OOT Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df[(df.date > '2016-01-14') & (df.date < '2016-11-01')].copy()\n",
    "oot = df[(df.date >= '2016-11-01')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tt.iloc[:,2:-1].values, tt.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOT Validation Data\n",
    "X_oot = oot.iloc[:,2:-1]\n",
    "y_oot = oot.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bunch of different train/test splits\n",
    "def gen_data(n = 5):\n",
    "    # Create n sets of train_test splits\n",
    "    dataTest = dict()\n",
    "    for i in range(n):\n",
    "        # i is the random seed used in each train/test split below\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y, random_state = i)\n",
    "        dataTest[i] = dict()\n",
    "        dataTest[i]['X_train'] = X_train\n",
    "        dataTest[i]['X_test'] = X_test\n",
    "        dataTest[i]['y_train'] = y_train\n",
    "        dataTest[i]['y_test'] = y_test\n",
    "        # Upsample minority class\n",
    "        df_resamp = pd.DataFrame(X_train, columns = [i for i in tt.columns if i not in ['fraud_label', 'date', 'record']])\n",
    "        df_resamp['fraud_label'] = y_train\n",
    "        # Separate majority/minority\n",
    "        df_majority = df_resamp[df_resamp.fraud_label == 0]\n",
    "        df_minority = df_resamp[df_resamp.fraud_label == 1]\n",
    "        # Upsample minority\n",
    "        df_minority_upsampled = resample(df_minority, replace = True, \n",
    "                                         n_samples = int(df_majority.fraud_label.count()), # Upsample so minority = majority\n",
    "                                         random_state = i)\n",
    "        # Combine\n",
    "        df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "        df_upsampled.fraud_label.value_counts()\n",
    "        dataTest[i]['X_train_upsampled'] = df_upsampled.iloc[:,:-1]\n",
    "        dataTest[i]['y_train_upsampled'] = df_upsampled.iloc[:,-1]\n",
    "    return dataTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining evaluation metric - FDR 3%\n",
    "def scoring(model, X_train, y_train, X_test, y_test, ootX, ootY, top_percent = 3):\n",
    "    train_pred = model.predict_proba(X_train)[:, 1]\n",
    "    train_actual_predict = pd.DataFrame({'pred': train_pred, 'actual': y_train})\n",
    "    fdr_train = (train_actual_predict.sort_values('pred', ascending=False) > 0.5).head(int(round(len(train_actual_predict) * 0.01 * top_percent)))['actual'].sum() / y_train.sum()\n",
    "    \n",
    "    test_pred = model.predict_proba(X_test)[:, 1]\n",
    "    test_actual_predict = pd.DataFrame({'pred': test_pred, 'actual': y_test})\n",
    "    fdr_test = (test_actual_predict.sort_values('pred', ascending=False) > 0.5).head(int(round(len(test_actual_predict) * 0.01 * top_percent)))['actual'].sum() / y_test.sum()\n",
    "    \n",
    "    oot_pred = model.predict_proba(X_oot)[:, 1]\n",
    "    oot_actual_predict = pd.DataFrame({'pred': oot_pred, 'actual': y_oot}) \n",
    "    fdr_oot = (oot_actual_predict.sort_values('pred', ascending=False) > 0.5).head(int(round(len(oot_actual_predict) * 0.01 * top_percent)))['actual'].sum() / y_oot.sum()\n",
    "    \n",
    "    scoring_df = {'Name': type(model).__name__, 'Training FDR': fdr_train, 'Test FDR': fdr_test, 'OOT_FDR': fdr_oot}\n",
    "    \n",
    "    return scoring_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic\n",
    "mlog = LogisticRegression()\n",
    "\n",
    "# Random Forest - Coggeshall Params\n",
    "mrf1 = RandomForestClassifier(n_estimators=50, max_depth = 20, max_features = 10, verbose = True)\n",
    "\n",
    "# Random Forest - Andrew Params\n",
    "mrf2 = RandomForestClassifier(bootstrap = False, ccp_alpha = 0.0, class_weight = None, criterion = 'gini', \n",
    "                             max_depth = 5, max_features = 5, max_leaf_nodes = None, max_samples = None,\n",
    "                             min_impurity_decrease = 0.0, min_impurity_split = None, min_samples_leaf = 2,\n",
    "                             min_samples_split = 3, min_weight_fraction_leaf = 0.0, n_estimators = 100,\n",
    "                             n_jobs = None, oob_score = False, random_state = None, verbose = 0, \n",
    "                             warm_start = False)\n",
    "\n",
    "# Neural Net - Coggeshall Params\n",
    "mnn1 = MLPClassifier(solver ='lbfgs', alpha=1e-5, hidden_layer_sizes=(6,), random_state=1, verbose = True)\n",
    "\n",
    "# Neural Net - Andrew Params\n",
    "mnn2 = MLPClassifier(solver = 'adam', learning_rate = 'adaptive', \n",
    "                          hidden_layer_sizes = (15,20), alpha = 0.0001, activation = 'tanh')\n",
    "\n",
    "# Decision Tree\n",
    "mt = DecisionTreeClassifier(min_samples_split = 300, min_samples_leaf = 60,random_state = 1)\n",
    "\n",
    "# Boosted Trees\n",
    "mada1 = AdaBoostClassifier(learning_rate = 0.001, random_state = 1)\n",
    "mada2 = AdaBoostClassifier(learning_rate = 0.002, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    main_start = time.time()\n",
    "    # Change n to the number of different test/train data sets you want to create\n",
    "    avg_train, avg_test, avg_oot = 0, 0, 0\n",
    "    n = len(data)\n",
    "    for i,v in data.items():\n",
    "        print(f'Running Iteration: {i}')\n",
    "        inter_start = time.time()\n",
    "        model.fit(v['X_train_upsampled'], v['y_train_upsampled'])\n",
    "        scores = scoring(model = model, top_percent = 3, \n",
    "                      X_train = v['X_train'], y_train = v['y_train'],\n",
    "                      X_test = v['X_test'], y_test = v['y_test'],\n",
    "                      ootX = X_oot, ootY = y_oot)\n",
    "        avg_train += scores['Training FDR']\n",
    "        avg_test += scores['Test FDR']\n",
    "        avg_oot += scores['OOT_FDR']\n",
    "        inter_end = time.time()\n",
    "        print(f' -Done: {round(inter_end-inter_start, 5)}s')\n",
    "    main_end = time.time()\n",
    "    print()\n",
    "    print('Average FDRs:')\n",
    "    print(f' -Train: {round(avg_train/n,4)}')\n",
    "    print(f' -Test: {round(avg_test/n,4)}')\n",
    "    print(f' -OOT: {round(avg_oot/n,4)}')\n",
    "    print(f'Total Runtime: {round(main_end-main_start, 5)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen 3 Diff Train/Test splits\n",
    "testdata = gen_data(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -Done: 10.91377s\n",
      "Running Iteration: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -Done: 10.73528s\n",
      "Running Iteration: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -Done: 10.52385s\n",
      "\n",
      "Average FDRs:\n",
      " -Train: 0.5302\n",
      " -Test: 0.5183\n",
      " -OOT: 0.5095\n",
      "Total Runtime: 32.17689s\n"
     ]
    }
   ],
   "source": [
    "test_model(mlog, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "test_model(mrf1, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(mrf2, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(mnn1, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(mnn2, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(mt, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(mada1, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(mada2, testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
